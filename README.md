# ðŸš€ Real-Time Sales Streaming Pipeline

A real-time data streaming pipeline built using **Apache Kafka**, **PySpark Structured Streaming**, and **Docker**.

This project simulates live sales events, streams them through Kafka, and performs real-time window-based revenue aggregation using Spark.

---

## ðŸ“Œ Project Overview

This pipeline demonstrates how real-time data flows through a distributed system:

Python Producer â†’ Kafka Broker â†’ PySpark Structured Streaming â†’ Window Aggregation

The system processes streaming sales events and calculates total revenue per city in fixed time windows.

---

## ðŸ›  Tech Stack

- Python 3.12
- Apache Kafka
- ZooKeeper
- PySpark 4.0.1
- Docker & Docker Compose
- Structured Streaming (Event-Time Processing)

---

## ðŸ”¥ Features

- Real-time JSON event generation
- Kafka topic-based messaging
- Spark Structured Streaming integration
- Event-time windowed aggregation
- Watermark support
- Dockerized Kafka infrastructure
- Micro-batch streaming execution

---

## â–¶ How To Run This Project

- pip install -r requirements.txt
- cd docker
- docker-compose up -d
- python producer/DataProducer.py
- python consumer/SparkConsumer.py